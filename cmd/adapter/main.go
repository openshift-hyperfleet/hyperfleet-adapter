package main

import (
	"context"
	"flag"
	"fmt"
	"os"
	"os/signal"
	"syscall"
	"time"

	"github.com/openshift-hyperfleet/hyperfleet-adapter/internal/config_loader"
	"github.com/openshift-hyperfleet/hyperfleet-adapter/internal/dryrun"
	"github.com/openshift-hyperfleet/hyperfleet-adapter/internal/executor"
	"github.com/openshift-hyperfleet/hyperfleet-adapter/internal/hyperfleet_api"
	"github.com/openshift-hyperfleet/hyperfleet-adapter/internal/k8s_client"
	"github.com/openshift-hyperfleet/hyperfleet-adapter/internal/maestro_client"
	"github.com/openshift-hyperfleet/hyperfleet-adapter/internal/transport_client"
	"github.com/openshift-hyperfleet/hyperfleet-adapter/pkg/health"
	"github.com/openshift-hyperfleet/hyperfleet-adapter/pkg/logger"
	"github.com/openshift-hyperfleet/hyperfleet-adapter/pkg/otel"
	"github.com/openshift-hyperfleet/hyperfleet-adapter/pkg/version"
	"github.com/openshift-hyperfleet/hyperfleet-broker/broker"
	"github.com/spf13/cobra"
	"github.com/spf13/pflag"
	"gopkg.in/yaml.v3"
)

// Command-line flags
var (
	configPath     string // Path to deployment config (adapter-config.yaml)
	taskConfigPath string // Path to task config (adapter-task-config.yaml)
	logLevel       string
	logFormat      string
	logOutput      string
	serveFlags     *pflag.FlagSet

	// Dry-run flags
	dryRunEvent        string // Path to CloudEvent JSON file
	dryRunAPIResponses string // Path to mock API responses JSON file
	dryRunDiscovery    string // Path to mock discovery responses JSON file
	dryRunVerbose      bool   // Show verbose dry-run output
	dryRunOutput       string // Output format: text or json
)

// Timeout constants
const (
	// OTelShutdownTimeout is the timeout for gracefully shutting down the OpenTelemetry TracerProvider
	OTelShutdownTimeout = 5 * time.Second
	// HealthServerShutdownTimeout is the timeout for gracefully shutting down the health server
	HealthServerShutdownTimeout = 5 * time.Second
)

// Server port constants
const (
	// HealthServerPort is the port for /healthz and /readyz endpoints
	HealthServerPort = "8080"
	// MetricsServerPort is the port for /metrics endpoint
	MetricsServerPort = "9090"
)

func main() {
	// Root command
	rootCmd := &cobra.Command{
		Use:   "adapter",
		Short: "HyperFleet Adapter - event-driven Kubernetes resource manager",
		Long: `HyperFleet Adapter listens for events from a message broker and
executes configured actions including Kubernetes resource management
and HyperFleet API calls.`,
		// Disable default completion command
		CompletionOptions: cobra.CompletionOptions{
			DisableDefaultCmd: true,
		},
	}

	// Add flags to root command (so they work on all subcommands)
	pflag.CommandLine.AddGoFlagSet(flag.CommandLine)

	// Serve command
	serveCmd := &cobra.Command{
		Use:   "serve",
		Short: "Start the adapter and begin processing events",
		Long: `Start the HyperFleet adapter in serve mode. The adapter will:
- Connect to the configured message broker
- Subscribe to the specified topic
- Process incoming events according to the adapter configuration
- Execute Kubernetes operations and HyperFleet API calls

Dry-run mode:
  Pass --dry-run-event to process a single CloudEvent from a JSON file
  using mock transport clients. No broker, cluster, or API is required.
  Optionally pass --dry-run-api-responses to configure mock API responses.`,
		RunE: func(cmd *cobra.Command, args []string) error {
			if isDryRun() {
				return runDryRun()
			}
			return runServe()
		},
	}

	// Add config flags to serve command
	serveCmd.Flags().StringVarP(&configPath, "config", "c", "",
		fmt.Sprintf("Path to adapter deployment config file (can also use %s env var)", config_loader.EnvAdapterConfig))
	serveCmd.Flags().StringVarP(&taskConfigPath, "task-config", "t", "",
		fmt.Sprintf("Path to adapter task config file (can also use %s env var)", config_loader.EnvTaskConfigPath))
	serveFlags = serveCmd.Flags()

	// Add Maestro override flags
	serveCmd.Flags().String("maestro-grpc-server-address", "", "Maestro gRPC server address")
	serveCmd.Flags().String("maestro-http-server-address", "", "Maestro HTTP server address")
	serveCmd.Flags().String("maestro-source-id", "", "Maestro source ID")
	serveCmd.Flags().String("maestro-client-id", "", "Maestro client ID")
	serveCmd.Flags().String("maestro-ca-file", "", "Maestro CA certificate file")
	serveCmd.Flags().String("maestro-cert-file", "", "Maestro client certificate file")
	serveCmd.Flags().String("maestro-key-file", "", "Maestro client key file")
	serveCmd.Flags().String("maestro-timeout", "", "Maestro client timeout")
	serveCmd.Flags().Bool("maestro-insecure", false, "Use insecure connection to Maestro")

	// Add HyperFleet API override flags
	serveCmd.Flags().String("hyperfleet-api-timeout", "", "HyperFleet API timeout")
	serveCmd.Flags().Int("hyperfleet-api-retry", 0, "HyperFleet API retry attempts")

	// Add config debug override flags
	serveCmd.Flags().Bool("debug-config", false,
		"Log the full merged configuration after load. Env: HYPERFLEET_DEBUG_CONFIG")

	// Add logging flags to serve command
	serveCmd.Flags().StringVar(&logLevel, "log-level", "",
		"Log level (debug, info, warn, error). Env: LOG_LEVEL")
	serveCmd.Flags().StringVar(&logFormat, "log-format", "",
		"Log format (text, json). Env: LOG_FORMAT")
	serveCmd.Flags().StringVar(&logOutput, "log-output", "",
		"Log output (stdout, stderr). Env: LOG_OUTPUT")

	// Add dry-run flags to serve command
	serveCmd.Flags().StringVar(&dryRunEvent, "dry-run-event", "",
		"Path to CloudEvent JSON file for dry-run mode")
	serveCmd.Flags().StringVar(&dryRunAPIResponses, "dry-run-api-responses", "",
		"Path to mock API responses JSON file for dry-run mode (defaults to 200 OK)")
	serveCmd.Flags().StringVar(&dryRunDiscovery, "dry-run-discovery", "",
		"Path to mock discovery responses JSON file for dry-run mode (overrides applied resources by name)")
	serveCmd.Flags().BoolVar(&dryRunVerbose, "dry-run-verbose", false,
		"Show rendered manifests, API request/response bodies in dry-run output")
	serveCmd.Flags().StringVar(&dryRunOutput, "dry-run-output", "text",
		"Dry-run output format: text or json")

	// Version command
	versionCmd := &cobra.Command{
		Use:   "version",
		Short: "Print version information",
		Run: func(cmd *cobra.Command, args []string) {
			info := version.Info()
			fmt.Printf("HyperFleet Adapter\n")
			fmt.Printf("  Version:    %s\n", info.Version)
			fmt.Printf("  Commit:     %s\n", info.Commit)
			fmt.Printf("  Built:      %s\n", info.BuildDate)
			fmt.Printf("  Tag:        %s\n", info.Tag)
		},
	}

	// Add subcommands
	rootCmd.AddCommand(serveCmd)
	rootCmd.AddCommand(versionCmd)

	// Execute
	if err := rootCmd.Execute(); err != nil {
		os.Exit(1)
	}
}

// isDryRun returns true when dry-run flags are present.
func isDryRun() bool {
	return dryRunEvent != "" || dryRunAPIResponses != ""
}

// -----------------------------------------------------------------------------
// Configuration loading (shared between serve and dry-run)
// -----------------------------------------------------------------------------

// buildLoggerConfig creates a logger configuration from environment variables
// and command-line flags. Flags take precedence over environment variables.
func buildLoggerConfig(component string) logger.Config {
	cfg := logger.ConfigFromEnv()

	// Override with command-line flags if provided
	if logLevel != "" {
		cfg.Level = logLevel
	}
	if logFormat != "" {
		cfg.Format = logFormat
	}
	if logOutput != "" {
		cfg.Output = logOutput
	}

	cfg.Component = component
	cfg.Version = version.Version

	return cfg
}

// loadConfig loads the unified adapter configuration from both config files.
func loadConfig(ctx context.Context, log logger.Logger) (*config_loader.Config, error) {
	log.Info(ctx, "Loading adapter configuration...")
	config, err := config_loader.LoadConfig(
		config_loader.WithAdapterConfigPath(configPath),
		config_loader.WithTaskConfigPath(taskConfigPath),
		config_loader.WithAdapterVersion(version.Version),
		config_loader.WithFlags(serveFlags),
	)
	if err != nil {
		errCtx := logger.WithErrorField(ctx, err)
		log.Errorf(errCtx, "Failed to load adapter configuration")
		return nil, fmt.Errorf("failed to load adapter configuration: %w", err)
	}
	return config, nil
}

// -----------------------------------------------------------------------------
// Client creation (shared between serve and dry-run)
// -----------------------------------------------------------------------------

// createAPIClient creates a HyperFleet API client from the config
func createAPIClient(apiConfig config_loader.HyperfleetAPIConfig, log logger.Logger) (hyperfleet_api.Client, error) {
	var opts []hyperfleet_api.ClientOption

	// Set base URL if configured (env fallback handled in NewClient)
	if apiConfig.BaseURL != "" {
		opts = append(opts, hyperfleet_api.WithBaseURL(apiConfig.BaseURL))
	}

	// Set timeout if configured (0 means use default)
	if apiConfig.Timeout > 0 {
		opts = append(opts, hyperfleet_api.WithTimeout(apiConfig.Timeout))
	}

	// Set retry attempts
	if apiConfig.RetryAttempts > 0 {
		opts = append(opts, hyperfleet_api.WithRetryAttempts(apiConfig.RetryAttempts))
	}

	// Set retry backoff strategy
	if apiConfig.RetryBackoff != "" {
		switch apiConfig.RetryBackoff {
		case hyperfleet_api.BackoffExponential, hyperfleet_api.BackoffLinear, hyperfleet_api.BackoffConstant:
			opts = append(opts, hyperfleet_api.WithRetryBackoff(apiConfig.RetryBackoff))
		default:
			return nil, fmt.Errorf("invalid retry backoff strategy %q (supported: exponential, linear, constant)", apiConfig.RetryBackoff)
		}
	}

	// Set retry base delay
	if apiConfig.BaseDelay > 0 {
		opts = append(opts, hyperfleet_api.WithBaseDelay(apiConfig.BaseDelay))
	}

	// Set retry max delay
	if apiConfig.MaxDelay > 0 {
		opts = append(opts, hyperfleet_api.WithMaxDelay(apiConfig.MaxDelay))
	}

	// Set default headers
	for key, value := range apiConfig.DefaultHeaders {
		opts = append(opts, hyperfleet_api.WithDefaultHeader(key, value))
	}

	return hyperfleet_api.NewClient(log, opts...)
}

// createTransportClient creates the appropriate transport client based on config.
func createTransportClient(ctx context.Context, config *config_loader.Config, log logger.Logger) (transport_client.TransportClient, error) {
	if config.Spec.Clients.Maestro != nil {
		log.Info(ctx, "Creating Maestro transport client...")
		client, err := createMaestroClient(ctx, config.Spec.Clients.Maestro, log)
		if err != nil {
			return nil, fmt.Errorf("failed to create Maestro client: %w", err)
		}
		log.Info(ctx, "Maestro transport client created successfully")
		return client, nil
	}

	log.Info(ctx, "Creating Kubernetes transport client...")
	client, err := createK8sClient(ctx, config.Spec.Clients.Kubernetes, log)
	if err != nil {
		return nil, fmt.Errorf("failed to create Kubernetes client: %w", err)
	}
	log.Info(ctx, "Kubernetes transport client created successfully")
	return client, nil
}

// createK8sClient creates a Kubernetes client from the config
func createK8sClient(ctx context.Context, k8sConfig config_loader.KubernetesConfig, log logger.Logger) (*k8s_client.Client, error) {
	clientConfig := k8s_client.ClientConfig{
		KubeConfigPath: k8sConfig.KubeConfigPath,
		QPS:            k8sConfig.QPS,
		Burst:          k8sConfig.Burst,
	}
	return k8s_client.NewClient(ctx, clientConfig, log)
}

// createMaestroClient creates a Maestro client from the config
func createMaestroClient(ctx context.Context, maestroConfig *config_loader.MaestroClientConfig, log logger.Logger) (*maestro_client.Client, error) {
	config := &maestro_client.Config{
		MaestroServerAddr: maestroConfig.HTTPServerAddress,
		GRPCServerAddr:    maestroConfig.GRPCServerAddress,
		SourceID:          maestroConfig.SourceID,
		Insecure:          maestroConfig.Insecure,
	}

	// Set TLS config if present
	if maestroConfig.Auth.TLSConfig != nil {
		config.CAFile = maestroConfig.Auth.TLSConfig.CAFile
		config.ClientCertFile = maestroConfig.Auth.TLSConfig.CertFile
		config.ClientKeyFile = maestroConfig.Auth.TLSConfig.KeyFile
	}

	return maestro_client.NewMaestroClient(ctx, config, log)
}

// buildExecutor creates the executor with the given clients.
func buildExecutor(config *config_loader.Config, apiClient hyperfleet_api.Client, tc transport_client.TransportClient, log logger.Logger) (*executor.Executor, error) {
	return executor.NewBuilder().
		WithConfig(config).
		WithAPIClient(apiClient).
		WithTransportClient(tc).
		WithLogger(log).
		Build()
}

// -----------------------------------------------------------------------------
// Serve mode (normal operation)
// -----------------------------------------------------------------------------

// runServe contains the main application logic for the serve command
func runServe() error {
	// Create context that cancels on system signals
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	// Create bootstrap logger (before config is loaded)
	log, err := logger.NewLogger(buildLoggerConfig("hyperfleet-adapter"))
	if err != nil {
		return fmt.Errorf("failed to create logger: %w", err)
	}

	log.Infof(ctx, "Starting Hyperfleet Adapter version=%s commit=%s built=%s tag=%s", version.Version, version.Commit, version.BuildDate, version.Tag)

	// Load unified configuration (deployment + task configs)
	config, err := loadConfig(ctx, log)
	if err != nil {
		return err
	}

	// Recreate logger with component name from config
	log, err = logger.NewLogger(buildLoggerConfig(config.Metadata.Name))
	if err != nil {
		return fmt.Errorf("failed to create logger with adapter config: %w", err)
	}

	log.Infof(ctx, "Adapter configuration loaded successfully: name=%s ",
		config.Metadata.Name)
	log.Infof(ctx, "HyperFleet API client configured: timeout=%s retryAttempts=%d",
		config.Spec.Clients.HyperfleetAPI.Timeout.String(),
		config.Spec.Clients.HyperfleetAPI.RetryAttempts)
	if config.Spec.DebugConfig {
		configBytes, err := yaml.Marshal(config)
		if err != nil {
			errCtx := logger.WithErrorField(ctx, err)
			log.Warnf(errCtx, "Failed to marshal adapter configuration for logging")
		} else {
			log.Infof(ctx, "Loaded adapter configuration:\n%s", string(configBytes))
		}
	}

	// Initialize OpenTelemetry
	sampleRatio := otel.GetTraceSampleRatio(log, ctx)
	tp, err := otel.InitTracer(config.Metadata.Name, version.Version, sampleRatio)
	if err != nil {
		errCtx := logger.WithErrorField(ctx, err)
		log.Errorf(errCtx, "Failed to initialize OpenTelemetry")
		return fmt.Errorf("failed to initialize OpenTelemetry: %w", err)
	}
	defer func() {
		shutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), OTelShutdownTimeout)
		defer shutdownCancel()
		if err := tp.Shutdown(shutdownCtx); err != nil {
			errCtx := logger.WithErrorField(shutdownCtx, err)
			log.Warnf(errCtx, "Failed to shutdown TracerProvider")
		}
	}()

	// Start health server
	healthServer := health.NewServer(log, HealthServerPort, config.Metadata.Name)
	if err := healthServer.Start(ctx); err != nil {
		errCtx := logger.WithErrorField(ctx, err)
		log.Errorf(errCtx, "Failed to start health server")
		return fmt.Errorf("failed to start health server: %w", err)
	}
	healthServer.SetConfigLoaded()
	defer func() {
		shutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), HealthServerShutdownTimeout)
		defer shutdownCancel()
		if err := healthServer.Shutdown(shutdownCtx); err != nil {
			errCtx := logger.WithErrorField(shutdownCtx, err)
			log.Warnf(errCtx, "Failed to shutdown health server")
		}
	}()

	// Start metrics server
	metricsServer := health.NewMetricsServer(log, MetricsServerPort, health.MetricsConfig{
		Component: config.Metadata.Name,
		Version:   version.Version,
		Commit:    version.Commit,
	})
	if err := metricsServer.Start(ctx); err != nil {
		errCtx := logger.WithErrorField(ctx, err)
		log.Errorf(errCtx, "Failed to start metrics server")
		return fmt.Errorf("failed to start metrics server: %w", err)
	}
	defer func() {
		shutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), HealthServerShutdownTimeout)
		defer shutdownCancel()
		if err := metricsServer.Shutdown(shutdownCtx); err != nil {
			errCtx := logger.WithErrorField(shutdownCtx, err)
			log.Warnf(errCtx, "Failed to shutdown metrics server")
		}
	}()

	// Create real clients
	log.Info(ctx, "Creating HyperFleet API client...")
	apiClient, err := createAPIClient(config.Spec.Clients.HyperfleetAPI, log)
	if err != nil {
		errCtx := logger.WithErrorField(ctx, err)
		log.Errorf(errCtx, "Failed to create HyperFleet API client")
		return fmt.Errorf("failed to create HyperFleet API client: %w", err)
	}

	tc, err := createTransportClient(ctx, config, log)
	if err != nil {
		errCtx := logger.WithErrorField(ctx, err)
		log.Errorf(errCtx, "Failed to create transport client")
		return err
	}

	// Build executor
	log.Info(ctx, "Creating event executor...")
	exec, err := buildExecutor(config, apiClient, tc, log)
	if err != nil {
		errCtx := logger.WithErrorField(ctx, err)
		log.Errorf(errCtx, "Failed to create executor")
		return fmt.Errorf("failed to create executor: %w", err)
	}

	// Create the event handler and subscribe to broker
	handler := exec.CreateHandler()

	// Handle signals for graceful shutdown
	sigCh := make(chan os.Signal, 1)
	signal.Notify(sigCh, syscall.SIGINT, syscall.SIGTERM)
	go func() {
		sig := <-sigCh
		log.Infof(ctx, "Received signal %s, initiating graceful shutdown...", sig)
		log.Info(ctx, "Shutdown initiated, marking not ready")
		healthServer.SetShuttingDown(true)
		cancel()

		// Second signal forces immediate exit
		sig = <-sigCh
		log.Infof(ctx, "Received second signal %s, forcing immediate exit", sig)
		os.Exit(1)
	}()

	// Get broker config
	subscriptionID := config.Spec.Clients.Broker.SubscriptionID
	if subscriptionID == "" {
		err := fmt.Errorf("spec.clients.broker.subscriptionId is required")
		errCtx := logger.WithErrorField(ctx, err)
		log.Errorf(errCtx, "Missing required broker configuration")
		return err
	}

	topic := config.Spec.Clients.Broker.Topic
	if topic == "" {
		err := fmt.Errorf("spec.clients.broker.topic is required")
		errCtx := logger.WithErrorField(ctx, err)
		log.Errorf(errCtx, "Missing required broker configuration")
		return err
	}

	// Create broker subscriber and subscribe
	log.Info(ctx, "Creating broker subscriber...")
	subscriber, err := broker.NewSubscriber(log, subscriptionID)
	if err != nil {
		errCtx := logger.WithErrorField(ctx, err)
		log.Errorf(errCtx, "Failed to create subscriber")
		return fmt.Errorf("failed to create subscriber: %w", err)
	}
	log.Info(ctx, "Broker subscriber created successfully")

	log.Info(ctx, "Subscribing to broker topic...")
	err = subscriber.Subscribe(ctx, topic, handler)
	if err != nil {
		errCtx := logger.WithErrorField(ctx, err)
		log.Errorf(errCtx, "Failed to subscribe to topic")
		return fmt.Errorf("failed to subscribe to topic: %w", err)
	}
	log.Info(ctx, "Successfully subscribed to broker topic")

	// Mark as ready
	healthServer.SetBrokerReady(true)
	log.Info(ctx, "Adapter is ready to process events")

	// Monitor subscription errors
	fatalErrCh := make(chan error, 1)
	go func() {
		for subErr := range subscriber.Errors() {
			errCtx := logger.WithErrorField(ctx, subErr)
			log.Errorf(errCtx, "Subscription error")
			select {
			case fatalErrCh <- subErr:
			default:
			}
		}
	}()

	log.Info(ctx, "Adapter started, waiting for events...")

	// Wait for shutdown signal or fatal subscription error
	select {
	case <-ctx.Done():
		log.Info(ctx, "Context cancelled, shutting down...")
	case err := <-fatalErrCh:
		errCtx := logger.WithErrorField(ctx, err)
		log.Errorf(errCtx, "Fatal subscription error, shutting down")
		healthServer.SetShuttingDown(true)
		cancel()
	}

	// Close subscriber gracefully
	log.Info(ctx, "Closing broker subscriber...")
	shutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer shutdownCancel()

	closeDone := make(chan error, 1)
	go func() {
		closeDone <- subscriber.Close()
	}()

	select {
	case err := <-closeDone:
		if err != nil {
			errCtx := logger.WithErrorField(ctx, err)
			log.Errorf(errCtx, "Error closing subscriber")
		} else {
			log.Info(ctx, "Subscriber closed successfully")
		}
	case <-shutdownCtx.Done():
		err := fmt.Errorf("subscriber close timed out after 30 seconds")
		errCtx := logger.WithErrorField(ctx, err)
		log.Error(errCtx, "Subscriber close timed out")
	}

	log.Info(ctx, "Adapter shutdown complete")

	return nil
}

// -----------------------------------------------------------------------------
// Dry-run mode
// -----------------------------------------------------------------------------

// runDryRun processes a single CloudEvent from file using mock clients.
func runDryRun() error {
	ctx := context.Background()

	// Create logger on stderr so stdout is reserved for trace output
	log, err := logger.NewLogger(logger.Config{
		Level:     "warn",
		Format:    "text",
		Output:    "stderr",
		Component: "dry-run",
	})
	if err != nil {
		return fmt.Errorf("failed to create logger: %w", err)
	}

	// Load config (same path as serve)
	config, err := loadConfig(ctx, log)
	if err != nil {
		return err
	}

	// Load CloudEvent from file
	if dryRunEvent == "" {
		return fmt.Errorf("--dry-run-event is required for dry-run mode")
	}
	evt, err := dryrun.LoadCloudEvent(dryRunEvent)
	if err != nil {
		return fmt.Errorf("failed to load event: %w", err)
	}

	// Create dryrun API client
	var dryrunResponsesFile *dryrun.DryrunResponsesFile
	if dryRunAPIResponses != "" {
		dryrunResponsesFile, err = dryrun.LoadDryrunResponses(dryRunAPIResponses)
		if err != nil {
			return fmt.Errorf("failed to load dryrun responses: %w", err)
		}
	}
	dryrunAPI, err := dryrun.NewDryrunAPIClient(dryrunResponsesFile)
	if err != nil {
		return fmt.Errorf("failed to create dryrun API client: %w", err)
	}

	// Create recording transport client
	var dryrunClient *dryrun.DryrunTransportClient
	if dryRunDiscovery != "" {
		overrides, err := dryrun.LoadDiscoveryOverrides(dryRunDiscovery)
		if err != nil {
			return fmt.Errorf("failed to load discovery overrides: %w", err)
		}
		dryrunClient = dryrun.NewDryrunTransportClientWithOverrides(overrides)
	} else {
		dryrunClient = dryrun.NewDryrunTransportClient()
	}

	// Build executor with mock clients (same builder as serve)
	exec, err := buildExecutor(config, dryrunAPI, dryrunClient, log)
	if err != nil {
		return fmt.Errorf("failed to create executor: %w", err)
	}

	// Execute with event data
	result := exec.Execute(ctx, evt.Data())

	// Build and output execution trace
	trace := &dryrun.ExecutionTrace{
		EventID:   evt.ID(),
		EventType: evt.Type(),
		Result:    result,
		APIClient: dryrunAPI,
		Transport: dryrunClient,
		Verbose:   dryRunVerbose,
	}

	switch dryRunOutput {
	case "json":
		data, err := trace.FormatJSON()
		if err != nil {
			return fmt.Errorf("failed to format trace as JSON: %w", err)
		}
		fmt.Println(string(data))
	default:
		fmt.Print(trace.FormatText())
	}

	if result.Status == executor.StatusFailed {
		for phase, err := range result.Errors {
			fmt.Fprintf(os.Stderr, "Error in %s: %v\n", phase, err)
		}
	}

	return nil
}
