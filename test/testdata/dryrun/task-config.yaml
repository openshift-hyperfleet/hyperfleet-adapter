# Task configuration for dry-run testing
apiVersion: hyperfleet.redhat.com/v1alpha1
kind: AdapterTaskConfig
metadata:
  name: dryrun-task
  labels:
    hyperfleet.io/adapter-type: dryrun

spec:
  params:
    - name: "clusterId"
      source: "event.id"
      type: "string"
      required: true

    - name: "clusterKind"
      source: "event.kind"
      type: "string"
      default: "Cluster"

    - name: "generationValue"
      source: "event.generation"
      type: "string"
      required: true

    - name: "region"
      source: "env.REGION"
      type: "string"
      default: "us-east-1"

    - name: "adapterName"
      source: "env.ADAPTER_NAME"
      type: "string"
      default: "dry-run-adapter"

  preconditions:
    - name: "fetch-cluster"
      apiCall:
        method: "GET"
        url: "/api/hyperfleet/v1/clusters/{{ .clusterId }}"
        timeout: 10s
      capture:
        - name: "clusterName"
          field: "name"
        - name: "clusterStatus"
          expression: |
            status.conditions.filter(c, c.type == "Ready").size() > 0
              ? status.conditions.filter(c, c.type == "Ready")[0].status
              : "False"
        - name: "computeNodes"
          field: "nodes.compute"
        #TODO: research why we can not have {{ now }} as expression
        - name: "timestamp"
          expression:  "\"2006-01-02T15:04:05Z07:00\""

      conditions:
        - field: "clusterStatus"
          operator: "notEquals"
          value: "True"

  resources:
    - name: "resource0"
      transport: 
        client: maestro
        maestro:
          targetCluster: cluster1
      manifest:
        apiVersion: work.open-cluster-management.io/v1
        kind: ManifestWork
        metadata:
          # ManifestWork name - must be unique within consumer namespace
          #name: "manifestwork-{{ .clusterId }}"
          name: "manifestwork-symbol000"

          # Labels for identification, filtering, and management
          labels:
            # HyperFleet tracking labels
            hyperfleet.io/cluster-id: "{{ .clusterId }}"
            hyperfleet.io/adapter: "{{ .adapterName }}"
            hyperfleet.io/component: "infrastructure"
            hyperfleet.io/generation: "{{ .generationValue }}"
            hyperfleet.io/resource-group: "cluster-setup"

            # Maestro-specific labels
            maestro.io/source-id: "{{ .adapterName }}"
            maestro.io/resource-type: "manifestwork"
            maestro.io/priority: "normal"

            # Standard Kubernetes application labels
            app.kubernetes.io/name: "aro-hcp-cluster"
            app.kubernetes.io/instance: "{{ .clusterId }}"
            app.kubernetes.io/version: "v1.0.0"
            app.kubernetes.io/component: "infrastructure"
            app.kubernetes.io/part-of: "hyperfleet"
            app.kubernetes.io/managed-by: "hyperfleet-adapter"
            app.kubernetes.io/created-by: "{{ .adapterName }}"

          # Annotations for metadata and operational information
          annotations:
            # Tracking and lifecycle
            hyperfleet.io/created-by: "hyperfleet-adapter-framework"
            hyperfleet.io/managed-by: "{{ .adapterName }}"
            hyperfleet.io/generation: "{{ .generationValue }}"
            hyperfleet.io/cluster-name: "{{ .clusterId }}"
            hyperfleet.io/deployment-time: "{{ .timestamp }}"

            # Maestro-specific annotations
            maestro.io/applied-time: "{{ .timestamp }}"
            maestro.io/source-adapter: "{{ .adapterName }}"

            # Operational annotations
            deployment.hyperfleet.io/strategy: "rolling"
            deployment.hyperfleet.io/timeout: "300s"
            monitoring.hyperfleet.io/enabled: "true"

            # Documentation
            description: "Complete cluster setup including namespace, configuration, and RBAC"
            documentation: "https://docs.hyperfleet.io/adapters/aro-hcp"

        # ManifestWork specification
        spec:
          # ============================================================================
          # Workload - Contains the Kubernetes manifests to deploy
          # ============================================================================
          workload:
            # Kubernetes manifests array - injected by framework from business logic config
            manifests:
            - apiVersion: v1
              kind: Namespace
              metadata:
                name: "{{ .clusterId | lower }}"
                labels:
                  hyperfleet.io/cluster-id: "{{ .clusterId }}"
                  hyperfleet.io/managed-by: "{{ .metadata.name }}"
                  hyperfleet.io/resource-type: "namespace"
                  hyperfleet.io/label-for-discovery: "namespace-symbol111"
                annotations:
                  hyperfleet.io/created-by: "hyperfleet-adapter"
                  hyperfleet.io/generation: "{{ .generationValue }}"
            - apiVersion: v1
              kind: ConfigMap
              metadata:
                name: "cluster-config"
                namespace: "{{ .clusterId }}-symbol222"
                labels:
                  hyperfleet.io/cluster-id: "{{ .clusterId }}"
                annotations:
                  hyperfleet.io/generation: "{{ .generationValue }}"
              data:
                cluster_id: "{{ .clusterId }}"
                cluster_name: "{{ .clusterName }}"

          # ============================================================================
          # Delete Options - How resources should be removed
          # ============================================================================
          deleteOption:
            # Propagation policy for resource deletion
            # - "Foreground": Wait for dependent resources to be deleted first
            # - "Background": Delete immediately, let cluster handle dependents
            # - "Orphan": Leave resources on cluster when ManifestWork is deleted
            propagationPolicy: "Foreground"

            # Grace period for graceful deletion (seconds)
            gracePeriodSeconds: 30

          # ============================================================================
          # Manifest Configurations - Per-resource settings for update and feedback
          # ============================================================================
          manifestConfigs:
            # ========================================================================
            # Configuration for Namespace resources
            # ========================================================================
            - resourceIdentifier:
                group: ""                           # Core API group (empty for v1 resources)
                resource: "namespaces"              # Resource type
                name: "{{ .clusterId | lower }}"    # Specific resource name
              updateStrategy:
                type: "ServerSideApply"             # Use server-side apply for namespaces
                serverSideApply:
                  fieldManager: "hyperfleet-adapter" # Field manager name for conflict resolution
                  force: false                      # Don't force conflicts (fail on conflicts)
              feedbackRules:
                - type: "JSONPaths"                 # Use JSON path expressions for status feedback
                  jsonPaths:
                    - name: "phase"                 # Namespace phase (Active, Terminating)
                      path: ".status.phase"
                    - name: "conditions"            # Namespace conditions array
                      path: ".status.conditions"
                    - name: "creationTimestamp"     # When namespace was created
                      path: ".metadata.creationTimestamp"

      discovery:
        namespace: "*"
        #byName: "cluster-{{ .clusterId }}-config"
        #byName: "manifestwork0"
        bySelectors:
          labelSelector:
            hyperfleet.io/resource-type: manifestwork

      # Discover sub-resources within the manifestWork
      # This approach can be used to use the discovery name to parameter level
      # This can support jsonPath to dig into the resource status. like discoveryNamespace.status.conditions[?(@.type=="Ready")].status
      nestedDiscoveries:
        - name: "discoveryNamespace"
          discovery:
            bySelectors:
              labelSelector:
                hyperfleet.io/label-for-discovery: "namespace-symbol111"
        - name: "discoveryConfigMap"
          discovery:
            byName: "{{ .clusterId }}-symbol222"

  post:
    payloads:
      - name: "statusPayload"
        build:
          conditions:
            - type: "Applied"
              status:
                expression: |
                  has(resources.resource0) && has(resources.resource0.discoveryNamespace) ? "True" : "False"
              reason:
                expression: |
                  resources.resource0.discoveryNamespace.metadata.name 
                  + ' / ' +
                  metadata.name

                  + ' / ' +
                  resources.resource0.discoveryConfigMap.metadata.name
              message:
                expression: |
                  has(resources.resource0) && has(resources.resource0.discoveryNamespace)
                    ? "Resources discovered successfully"
                    : "Discovery pending"
            - type: "Health"
              status:
                expression: |
                  adapter.?executionStatus.orValue("") == "success" ? "True" : "False"
              reason:
                expression: |
                  adapter.?errorReason.orValue("") != "" ? adapter.?errorReason.orValue("") : "Healthy"
              message:
                expression: |
                  adapter.?errorMessage.orValue("") != "" ? adapter.?errorMessage.orValue("") : "Adapter healthy"

    postActions:
      - name: "update-status"
        apiCall:
          method: "PATCH"
          url: "/api/hyperfleet/v1/clusters/{{ .clusterId }}/statuses"
          body: "{{ .statusPayload }}"
